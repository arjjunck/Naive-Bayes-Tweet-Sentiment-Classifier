{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e58736a-11ea-4a61-a677-bdd63e4c6b1e",
   "metadata": {},
   "source": [
    "**Multinomial Naive\n",
    "Bayes learning algorithm in Python to classify tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90266185-7306-4a25-86fa-927920d255a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7eab1-d77e-4d2c-a1e5-c2516485a12e",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad9feffb-fdf4-403a-88de-cc0b9c3071b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = '/Users/arjun/Downloads/Lab_Week2-3/dataFiles/train/trainPos.txt'\n",
    "train_neg = '/Users/arjun/Downloads/Lab_Week2-3/dataFiles/train/trainNeg.txt'\n",
    "test_pos = '/Users/arjun/Downloads/Lab_Week2-3/dataFiles/test/testPos.txt'\n",
    "test_neg = '/Users/arjun/Downloads/Lab_Week2-3/dataFiles/test/testNeg.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00412d2d-d215-4ca5-885c-815fcba28726",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_df = pd.read_csv(train_pos, header=None, names=['tweet'], encoding='latin-1', engine='python')\n",
    "\n",
    "train_neg_df = pd.read_csv(train_neg, header=None, names=['tweet'], encoding='latin-1', engine='python')\n",
    "\n",
    "test_pos_df = pd.read_csv(test_pos, header=None, names=['tweet'], encoding='latin-1', engine='python')\n",
    "\n",
    "test_neg_df = pd.read_csv(test_neg, header=None, names=['tweet'], encoding='latin-1', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4f685-594c-4fe0-b751-1bde1e9c1e06",
   "metadata": {},
   "source": [
    "**Stage 1: Vocabulary and Word Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79de2f12-1d92-4be7-876c-29eee1ae8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'[^a-z\\s]', '', tweet)\n",
    "    words = tweet.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1afdc977-48cd-4ec0-97d8-e56e967844c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary_and_frequencies(train_pos_df, train_neg_df):\n",
    "\n",
    "    vocab = set()\n",
    "    pos_dict = {}\n",
    "    neg_dict = {}\n",
    "\n",
    "    # positive tweets\n",
    "    for tweet in train_pos_df['tweet']:\n",
    "        words = preprocess(tweet)\n",
    "        for word in words:\n",
    "            vocab.add(word)\n",
    "            pos_dict[word] = pos_dict.get(word, 0) + 1\n",
    "\n",
    "    # negative tweets\n",
    "    for tweet in train_neg_df['tweet']:\n",
    "        words = preprocess(tweet)\n",
    "        for word in words:\n",
    "            vocab.add(word)\n",
    "            neg_dict[word] = neg_dict.get(word, 0) + 1\n",
    "\n",
    "    \n",
    "    for word in vocab:\n",
    "        if word not in pos_dict:\n",
    "            pos_dict[word] = 0\n",
    "        if word not in neg_dict:\n",
    "            neg_dict[word] = 0\n",
    "\n",
    "    print(\"Vocab size:\", len(vocab))\n",
    "    print(\"Total positive words:\", sum(pos_dict.values()))\n",
    "    print(\"Total negative words:\", sum(neg_dict.values()))\n",
    "\n",
    "    return vocab, pos_dict, neg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732486b-58e4-4752-80af-f6d51c4a5b71",
   "metadata": {},
   "source": [
    "**Stage 2: Word Probabilities (Multinomial NB with Laplace smoothing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a741abd4-981a-49a8-919d-e5693f913a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(vocab, pos_dict, neg_dict,\n",
    "                            num_pos_docs, num_neg_docs):\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    total_pos_words = sum(pos_dict.values())\n",
    "    total_neg_words = sum(neg_dict.values())\n",
    "\n",
    "    pos_prob = {}\n",
    "    neg_prob = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        pos_prob[word] = (pos_dict[word] + 1) / (total_pos_words + vocab_size)\n",
    "        neg_prob[word] = (neg_dict[word] + 1) / (total_neg_words + vocab_size)\n",
    "\n",
    "    total_docs = num_pos_docs + num_neg_docs\n",
    "    prior_pos = num_pos_docs / total_docs\n",
    "    prior_neg = num_neg_docs / total_docs\n",
    "\n",
    "    return pos_prob, neg_prob, prior_pos, prior_neg, total_pos_words, total_neg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ddee0-32eb-4ab9-a2e5-41a93242f60a",
   "metadata": {},
   "source": [
    "**Stage 3: Classify single tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad621076-4051-4e05-ba91-507cbc25bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tweet(tweet, vocab,\n",
    "                   pos_prob, neg_prob,\n",
    "                   prior_pos, prior_neg,\n",
    "                   total_pos_words, total_neg_words):\n",
    "\n",
    "    words = preprocess(tweet)\n",
    "\n",
    "    log_pos = math.log(prior_pos)\n",
    "    log_neg = math.log(prior_neg)\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            log_pos += math.log(pos_prob[word])\n",
    "            log_neg += math.log(neg_prob[word])\n",
    "        else:\n",
    "            log_pos += math.log(1 / (total_pos_words + vocab_size))\n",
    "            log_neg += math.log(1 / (total_neg_words + vocab_size))\n",
    "\n",
    "    return \"pos\" if log_pos > log_neg else \"neg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb134e1-99f4-4a53-9699-f6f6564862f1",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "854a014f-78a1-4864-8e11-0b78225cee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_pos_df, test_neg_df,\n",
    "             vocab, pos_prob, neg_prob,\n",
    "             prior_pos, prior_neg,\n",
    "             total_pos_words, total_neg_words):\n",
    "\n",
    "    correct_pos = 0\n",
    "    correct_neg = 0\n",
    "\n",
    "    # Positive test tweets\n",
    "    for tweet in test_pos_df['tweet']:\n",
    "        pred = classify_tweet(tweet, vocab,\n",
    "                              pos_prob, neg_prob,\n",
    "                              prior_pos, prior_neg,\n",
    "                              total_pos_words, total_neg_words)\n",
    "        if pred == \"pos\":\n",
    "            correct_pos += 1\n",
    "\n",
    "    # Negative test tweets\n",
    "    for tweet in test_neg_df['tweet']:\n",
    "        pred = classify_tweet(tweet, vocab,\n",
    "                              pos_prob, neg_prob,\n",
    "                              prior_pos, prior_neg,\n",
    "                              total_pos_words, total_neg_words)\n",
    "        if pred == \"neg\":\n",
    "            correct_neg += 1\n",
    "\n",
    "    pos_accuracy = correct_pos / len(test_pos_df)\n",
    "    neg_accuracy = correct_neg / len(test_neg_df)\n",
    "    avg_accuracy = (pos_accuracy + neg_accuracy) / 2\n",
    "\n",
    "    print(\"Positive Accuracy:\", round(pos_accuracy, 4))\n",
    "    print(\"Negative Accuracy:\", round(neg_accuracy, 4))\n",
    "    print(\"Average Accuracy:\", round(avg_accuracy, 4))\n",
    "\n",
    "    return pos_accuracy, neg_accuracy, avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf044c00-9f29-402b-bd26-d32f52dfd52b",
   "metadata": {},
   "source": [
    "**Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf4567e5-b10c-423e-9edc-e68b7f5c8ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 490317\n",
      "Total positive words: 5012555\n",
      "Total negative words: 5368482\n",
      "Positive Accuracy: 0.739\n",
      "Negative Accuracy: 0.82\n",
      "Average Accuracy: 0.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.739, 0.82, 0.7795)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocab, pos_dict, neg_dict = build_vocabulary_and_frequencies(train_pos_df, train_neg_df)\n",
    "\n",
    "\n",
    "pos_prob, neg_prob, prior_pos, prior_neg, total_pos_words, total_neg_words = calculate_probabilities(vocab, pos_dict, neg_dict,len(train_pos_df), len(train_neg_df))\n",
    "\n",
    "\n",
    "evaluate(test_pos_df, test_neg_df,vocab, pos_prob, neg_prob,prior_pos, prior_neg,total_pos_words, total_neg_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
